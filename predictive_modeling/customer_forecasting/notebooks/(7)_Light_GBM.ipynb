{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing required Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nfrom sklearn.model_selection import ParameterGrid, StratifiedKFold\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the data set and creating summy variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\npath = '../input/masterfinal/'\ndf = pd.read_csv(path+ 'master_final.csv')\nfinal_test = df.copy()\ndf.sort_values(by = ['air_store_id','calendar_date'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test['air_store_idcheck'] = final_test['air_store_id']\ndf1 = pd.get_dummies(df, columns = ['air_genre_name', 'air_area_name','month','year', 'dayofweek', 'week_of_month', 'air_store_id'])\nfinal_test_upd = pd.get_dummies(check1, columns = ['air_genre_name', 'air_area_name','month','year', 'dayofweek', 'week_of_month', 'air_store_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Creating train, test and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df1[pd.to_datetime(df1['calendar_date']) < pd.to_datetime('2017-04-23')] \nfinal_check = check[pd.to_datetime(check['calendar_date']) >= pd.to_datetime('2017-04-23')]\ndel(df2['day_of_week'])\ndel(df2['hpg_store_id'])\ndel(df2['earlist_open_date'])\ndf2.fillna(0, inplace = True)\ntest = df2[pd.to_datetime(df2['calendar_date']) >= pd.to_datetime('2017-03-15')]\ntrain = df2[pd.to_datetime(df2['calendar_date']) < pd.to_datetime('2017-03-15')]\ndel(train['calendar_date'])\ndel(test['calendar_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[test['closed_flag'] != 2]\nx_train = train.copy()\nx_test = test.copy()\ndel(x_train['visitors'])\ndel(x_test['visitors'])\ny_train = train['visitors']\ny_test = test['visitors']\ncolnames_train = x_train.columns \ncolnames_test = x_test.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_colnames = {}\ni = 1\nfor col in x_train.columns:\n    new_colnames[col] = 'feature'+ str(i)\n    i +=1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.rename(columns = new_colnames, inplace = True)\nx_test.rename(columns = new_colnames, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Creating datasets for LGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = lgb.Dataset(x_train, label= y_train)\nd_valid = lgb.Dataset(x_test, label = y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': ['rmsle','mean_squared_error'],\n    'max_depth': 6, \n    'learning_rate': 0.1,\n    'verbose': 0, \n    'num_leaves' : 20,\n    'early_stopping_round': 30}\nn_estimators = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting parameters for grid search"},{"metadata":{"trusted":true},"cell_type":"code","source":"gridParams = {\n    'learning_rate': [ 0.1,0.01,0.001,0.00001],\n    'num_leaves': [10,20,30,40,50],\n    'max_depth' :[5,10,15,20]\n}\nresult = {}\nresult_list = []\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Iterating the model over different parameters and finding the best model"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"num_iter = 0\nfor lr in gridParams['learning_rate']:\n    for num in gridParams['num_leaves']:\n        for dep in gridParams['max_depth']:\n            params['learning_rate'] = lr\n            params['num_leaves'] = num\n            params['max_depth'] = dep\n            model = lgb.train(params, d_train, n_estimators, valid_sets = [d_valid])\n            y_pred = model.predict(x_test, num_iteration = model.best_iteration)\n            for i in range(len(y_pred)):\n                if y_pred[i] < 0:\n                    y_pred[i]= 0\n            key_dic = 'LR: ' + str(lr) + ', nleaf: ' + str(num) + ', max_dep: ' + str(dep)\n            rmsl = (mean_squared_log_error(y_true = y_test,y_pred= y_pred))**0.5\n            result[key_dic] = rmsl\n            result_list.append(rmsl)\n            if num_iter ==0:\n                model_best = model \n                y_best_pred = y_pred\n            elif result_list[num_iter] == min(result_list):\n                model_best = model\n                y_best_pred = y_pred\n            num_iter += 1\n            print(num_iter, min(result_list))\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the characteristics of the best model and fine tuning the model again"},{"metadata":{"trusted":true},"cell_type":"code","source":"min(result, key = result.get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(result.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridParams2 = {'learning_rate': [0.1, 0.01, 1],\n 'num_leaves': [50,60,75,100],\n 'max_depth': [12,15,17]}\nresult2 = {}\nresult_list2 = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_iter2 = 0\nfor lr in gridParams2['learning_rate']:\n    for num in gridParams2['num_leaves']:\n        for dep in gridParams2['max_depth']:\n            params['learning_rate'] = lr\n            params['num_leaves'] = num\n            params['max_depth'] = dep\n            model = lgb.train(params, d_train, n_estimators, valid_sets = [d_valid])\n            y_pred = model.predict(x_test, num_iteration = model.best_iteration)\n            for i in range(len(y_pred)):\n                if y_pred[i] < 0:\n                    y_pred[i]= 0\n            key_dic = 'LR: ' + str(lr) + ', nleaf: ' + str(num) + ', max_dep: ' + str(dep)\n            rmsl = (mean_squared_log_error(y_true = y_test,y_pred= y_pred))**0.5\n            result2[key_dic] = rmsl\n            result_list2.append(rmsl)\n            if num_iter2 ==0:\n                model_best2 = model \n                y_best_pred2= y_pred\n            elif result_list2[num_iter2] == min(result_list2):\n                model_best2 = model\n                y_best_pred2 = y_pred\n            num_iter2 += 1\n            print(num_iter2)\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finidng the best model and reviewing the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"min(result2.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(result2, key = result2.get)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Storing results of both iterations"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_pd1 = pd.DataFrame(result.values(), index = result.keys()).reset_index().rename(columns= {'index': 'HyperParameter',0: 'RMSLE'})\nresult_pd1['iteration'] =1 \nresult_pd2 = pd.DataFrame(result.values(), index = result.keys()).reset_index().rename(columns= {'index': 'HyperParameter',0: 'RMSLE'})\nresult_pd2['iteration'] =2\nresults_lgb = pd.concat([result_pd1,result_pd2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the required metrics of the best model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error\nprint('R squared : ',r2_score(y_true = y_test, y_pred = y_best_pred2))\nprint('RMSLE: ',mean_squared_log_error(y_test, y_best_pred2)**0.5)\nprint('MSE: ',mean_squared_error(y_test, y_best_pred2))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'LR: 0.1, nleaf: 50, max_dep: 15'\n0.53577"},{"metadata":{},"cell_type":"markdown","source":"Saving the model for later use"},{"metadata":{"trusted":true},"cell_type":"code","source":" model_best2.save_model('model_best2.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst = lgb.Booster(model_file='../input/modelfile/model_best2 (1).txt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the best features"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bst.feature_importance())\nlgb_feature_imp = pd.DataFrame({'colname':colnames_train,'feat_imp':bst.feature_importance()})\nlgb_feature_imp.sort_values(by = ['feat_imp'], ascending = False, inplace = True)\nlgb_feature_imp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing the data set for final submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_upd2 = final_test_upd.copy()\nfinal_test_upd2.drop(columns = ['calendar_date','day_of_week','hpg_store_id','air_store_idcheck','visitors','earlist_open_date'], inplace = True)\nfinal_test_upd2['closed_flag'] = 0\nfinal_test_upd2.rename(columns = new_colnames, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_pred = bst.predict(final_test_upd2)\nfor i in range(len(y_final_pred)):\n    if y_final_pred[i]<0:\n        y_final_pred[i] = 0 \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test['final_index'] = final_test.apply(lambda x: str(x['air_store_idcheck']) + '_' + str(x['calendar_date']), axis = 1)\nsub_file = pd.merge(final_test[['final_index']],  pd.DataFrame(y_final_pred,index = final_check.index ), how = 'outer',left_index = True, right_index = True)\nsub_file.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_file.rename(columns = {'final_index': 'id',0:'visitors_pred'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the sample file from Kaggle, appending the predictions and saving the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/sample/sample_submission.csv')\nsub_file2 = sample_sub.merge(sub_file, how = 'inner', on = 'id')\nsub_file2= sub_file2.drop(columns = 'visitors').rename(columns = {'visitors_pred': 'visitors'})\nsub_file2.to_csv('Submission_File_Fazel_closed.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}